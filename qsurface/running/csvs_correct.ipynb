{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from itertools import permutations\n",
    "\n",
    "files = [f for f in listdir(\"C:/qarch/qsurface/data/monolithic\") if isfile(join(\"C:/qarch/qsurface/data/monolithic\", f))]\n",
    "new_location = [\"C:/qarch/qsurface/data/monolithic/normalized/\"+ f for f in files]\n",
    "FILES = [\"C:/qarch/qsurface/data/monolithic/\"+ f for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This block creates a separate dataframe and fills it up with the new combination of error string and uses\n",
    "the rest same values. And merges them later with a resetted index.'''\n",
    "\n",
    "for new_loc, location in zip(new_location, FILES):\n",
    "    data = pd.read_csv(location, sep=';')\n",
    "\n",
    "    data2 = pd.DataFrame(columns=data.columns)\n",
    "    for index, row in data.iterrows():\n",
    "        perms = [''.join(p) for p in set(permutations(row[\"error_config\"]))]\n",
    "        for permutation in perms:\n",
    "            if permutation == row[\"error_config\"]:\n",
    "                continue\n",
    "            else:\n",
    "                data2.loc[data2.shape[0]] = [permutation, row['lie'], row['p'], row['s'],0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "    data_merged = pd.concat([data, data2]).reset_index()\n",
    "    del data_merged['index']\n",
    "\n",
    "    '''Now we need to rescale the error permutation star and plaquette weights. And later normalize the whole superoperator.'''\n",
    "    # Finding the right weights\n",
    "\n",
    "    for index, row in data.iterrows():\n",
    "        perms = [''.join(p) for p in set(permutations(row[\"error_config\"]))]\n",
    "        n_perms = len(perms)\n",
    "\n",
    "        for index_f, row_f in data_merged.iterrows():\n",
    "            if row_f['error_config'] in perms and row_f['lie'] == row['lie']:\n",
    "                data_merged.loc[index_f,'p'] = row_f['p']/n_perms\n",
    "                data_merged.loc[index_f,'s'] = row_f['s']/n_perms\n",
    "\n",
    "    # Normalizing the whole CSV weights\n",
    "\n",
    "    psum = data_merged['p'].sum()\n",
    "    ssum = data_merged['s'].sum()\n",
    "\n",
    "    data_merged['p'] = data_merged['p'].div(psum)\n",
    "    data_merged['s'] = data_merged['s'].div(ssum)\n",
    "\n",
    "    data_merged.to_csv(new_loc, sep=';', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9741a63e3bbb66ce0aff41f9307f59d64508d67e9174abd017bb37ca15f82d9d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('qs_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
